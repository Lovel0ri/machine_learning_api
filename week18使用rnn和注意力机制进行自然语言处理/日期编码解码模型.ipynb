{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP3GTgu/t1UqpgOcyeH5l3P"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","\n","# 数据集\n","input_data = [\"2022年3月22日\", \"2021年7月4日\"]\n","output_data = [\"2022-3-22\", \"2021-7-4\"]\n","\n","# 建立词表\n","input_vocab = set((\"\".join(input_data)).split())\n","output_vocab = set((\"\".join(output_data)).split())\n","\n","id2word_input = list(input_vocab)\n","input2id = {c: i for i, c in enumerate(id2word_input)}\n","\n","id2word_output = list(output_vocab)\n","output2id = {c: i for i, c in enumerate(id2word_output)}\n","\n","# 超参数\n","hidden_size = 128\n","embedding_size = 64\n","batch_size = 64\n","epochs = 100\n","\n","# 构建编码器\n","def make_encoder(inputs, hidden_size, embedding_size):\n","    embedding = tf.Variable(tf.random_uniform([len(input_vocab), embedding_size], -1.0, 1.0))\n","    inputs = tf.nn.embedding_lookup(embedding, inputs)\n","    cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_size)\n","    _, final_state = tf.nn.dynamic_rnn(cell, inputs, dtype=tf.float32)\n","    return final_state\n","\n","# 构建解码器\n","def make_decoder(inputs, hidden_size, embedding_size, output_length, initial_state):\n","    embedding = tf.Variable(tf.random_uniform([len(output_vocab), embedding_size], -1.0, 1.0))\n","    inputs = tf.nn.embedding_lookup(embedding, inputs)\n","    cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_size)\n","    outputs, _ = tf.nn.dynamic_rnn(cell, inputs, initial_state=initial_state, dtype=tf.float32)\n","    dense_layer = tf.layers.Dense(len(output_vocab))\n","    logits = dense_layer(outputs)\n","    predictions = tf.argmax(logits, axis=2)\n","    return logits, predictions\n","\n","# 构建图\n","graph = tf.Graph()\n","with graph.as_default():\n","    # 输入数据\n","    inputs = tf.placeholder(tf.int32, [batch_size, None])\n","    outputs = tf.placeholder(tf.int32, [batch_size, None])\n","    output_length = tf.placeholder(tf.int32, [batch_size])\n","    # 编码器\n","    encoder_state = make_encoder(inputs, hidden_size, embedding_size)\n","    # 解码器\n","    decoder_inputs = tf.pad(outputs[:, :-1], [[0, 0], [1, 0]], constant_values=len(output_vocab) - 1)\n","    decoder_initial_state = encoder_state\n","    decoder_logits, decoder_predictions = make_decoder(decoder_inputs, hidden_size, embedding_size, output_length, decoder_initial_state)\n","    # 损失函数\n","    mask = tf.sequence_mask(output_length, dtype=tf.float32)\n","    loss = tf.contrib.seq2seq.sequence_loss(decoder_logits, outputs, mask)\n","    # 优化器\n","    optimizer = tf.train.AdamOptimizer().minimize(loss)\n","\n","# 训练模型\n","with tf.Session(graph=graph) as sess:\n","    sess.run(tf.global_variables_initializer())\n","    for epoch in range(epochs):\n","        epoch_loss = 0\n","        for i in range(0, len(input_data), batch_size):\n","            batch_input = [list(map(lambda x: input2id[x], sent.split())) for sent in input_data[i:i+batch_size]]\n","            batch_output = [list(map(lambda x: output2id[x], sent.split())) for sent in output_data[i:i+batch_size]]\n","            batch_output_length = [len(x) for x in batch_output]\n","            max_output_length = max(batch_output_length)\n","            batch_output = [x + [output2id[\"<PAD>\"]] * (max_output_length - len(x)) for x in batch_output]\n","            _, batch_loss = sess.run([optimizer, loss], feed_dict={\n","                inputs: batch_input,\n","                outputs: batch_output,\n","                output_length: batch_output_length\n","            })\n","            epoch_loss += batch_loss\n","        print(\"Epoch:\", epoch + 1, \"Loss:\", epoch_loss / len(input_data))\n","\n","    # 测试模型\n","    test_input = \"2030年6月1日\"\n","    test_input = [input2id[x] for x in test_input.split()]\n","    test_input = np.array(test_input).reshape([1, -1])\n","    test_output = np.zeros([1, len(test_input) + 1], dtype=np.int32)\n","    test_output[0, 0] = output2id[\"<GO>\"]\n","    for i in range(len(test_input)):\n","        test_input_length = np.array([len(test_input)]).reshape([1])\n","        test_logits = sess.run(decoder_logits, feed_dict={\n","            inputs: test_input,\n","            outputs: test_output,\n","            output_length: test_input_length\n","        })\n","        pred = np.argmax(test_logits, axis=2)\n","        test_output[0, i+1] = pred[0, i]\n","    test_output = [id2word_output[x] for x in test_output[0, :]]\n","    test_output = \"\".join(test_output[1:-1])\n","    print(\"%s -> %s\" % (test_input[0], test_output))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"id":"UtSLXSR5BRbp","executionInfo":{"status":"error","timestamp":1684936372783,"user_tz":-480,"elapsed":415,"user":{"displayName":"陈冰冰","userId":"11790981709466704139"}},"outputId":"139984a6-0001-47e3-b76a-f650b7e53744"},"execution_count":13,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-293166da52a7>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# 输入数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0moutput_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"QYin0vl0BR8j"},"execution_count":null,"outputs":[]}]}