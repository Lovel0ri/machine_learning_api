{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPzmJfdbygBWzeoDN7+ixjJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XJeS5Rptcmce","executionInfo":{"status":"ok","timestamp":1682617442899,"user_tz":-480,"elapsed":209,"user":{"displayName":"陈冰冰","userId":"11790981709466704139"}},"outputId":"a3fde1d2-45f2-4319-8040-268bc8a0ba8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 0, loss = 0.250007\n","epoch 10, loss = 0.250003\n","epoch 20, loss = 0.250001\n","epoch 30, loss = 0.250000\n","epoch 40, loss = 0.250000\n","epoch 50, loss = 0.250000\n","epoch 60, loss = 0.250000\n","epoch 70, loss = 0.250000\n","epoch 80, loss = 0.250000\n","epoch 90, loss = 0.250000\n","[[0.50001794 0.49999716 0.50000201]\n"," [0.50003315 0.49999478 0.49998327]\n"," [0.5000205  0.49999645 0.50001268]\n"," [0.50003572 0.49999407 0.49999394]]\n"]}],"source":["import numpy as np\n","\n","# 定义MLP类\n","class MLP():\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        \"\"\"\n","        :param input_dim: 输入层神经元数量\n","        :param hidden_dim: 隐藏层神经元数量\n","        :param output_dim: 输出层神经元数量\n","        \"\"\"\n","        self.input_dim = input_dim  # 输入层神经元数量\n","        self.hidden_dim = hidden_dim  # 隐藏层神经元数量\n","        self.output_dim = output_dim  # 输出层神经元数量\n","        # 初始化权重\n","        self.weights_1 = np.random.randn(input_dim, hidden_dim) * 0.01\n","        self.weights_2 = np.random.randn(hidden_dim, output_dim) * 0.01\n","        # 初始化偏差\n","        self.bias_1 = np.zeros((1, hidden_dim))\n","        self.bias_2 = np.zeros((1, output_dim))\n","\n","    def sigmoid(self, x):\n","        \"\"\"sigmoid函数\"\"\"\n","        return 1 / (1 + np.exp(-x))\n","\n","    def forward(self, X):\n","        \"\"\"前向传播\"\"\"\n","        self.a1 = np.dot(X, self.weights_1) + self.bias_1\n","        self.z1 = self.sigmoid(self.a1)\n","        self.a2 = np.dot(self.z1, self.weights_2) + self.bias_2\n","        self.y_hat = self.sigmoid(self.a2)\n","        return self.y_hat\n","\n","    def sigmoid_prime(self, x):\n","        \"\"\"sigmoid函数导数\"\"\"\n","        return x * (1 - x)\n","\n","    def backward(self, X, y, y_hat, learning_rate):\n","        \"\"\"反向传播\"\"\"\n","        delta_a2 = (y_hat - y) * self.sigmoid_prime(y_hat)\n","        delta_weights2 = np.dot(self.z1.T, delta_a2)\n","        delta_bias2 = np.sum(delta_a2, axis=0, keepdims=True)\n","\n","        delta_z1 = np.dot(delta_a2, self.weights_2.T) * self.sigmoid_prime(self.z1)\n","        delta_weights1 = np.dot(X.T, delta_z1)\n","        delta_bias1 = np.sum(delta_z1, axis=0, keepdims=True)\n","\n","        self.weights_1 -= learning_rate * delta_weights1\n","        self.weights_2 -= learning_rate * delta_weights2\n","        self.bias_1 -= learning_rate * delta_bias1\n","        self.bias_2 -= learning_rate * delta_bias2\n","\n","    def train(self, X, y, epochs, learning_rate):\n","        \"\"\"训练模型\"\"\"\n","        for i in range(epochs):\n","            y_hat = self.forward(X)\n","            self.backward(X, y, y_hat, learning_rate)\n","            if i % 10 == 0:\n","                loss = np.mean(np.square(y - y_hat))\n","                print(\"epoch %d, loss = %f\" % (i, loss))\n","\n","# 测试代码\n","if __name__ == '__main__':\n","    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","    y = np.array([[0], [1], [1], [0]])\n","    mlp = MLP(input_dim=2, hidden_dim=4, output_dim=3)\n","    mlp.train(X, y, epochs=100, learning_rate=0.1)\n","    print(mlp.forward(X))\n"]},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import train_test_split\n","\n","# 加载鸢尾花数据集\n","data = load_iris()\n","X = data.data\n","y = data.target\n","\n","# 将数据集划分为训练集和测试集\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,shuffle=True)\n","\n","# 定义 MLP 分类器\n","clf = MLPClassifier(hidden_layer_sizes=(10, 5), max_iter=1000)\n","# 表示这个 MLP 分类器包含两个隐层，第一个隐层包含 10 个神经元，第二个隐层包含 5 个神经元。\n","\n","# 训练模型\n","clf.fit(X_train, y_train)\n","\n","# 在测试集上评估模型表现\n","accuracy = clf.score(X_test, y_test)\n","print(\"Test Accuracy: \", accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b0bW3Rk6eAdi","executionInfo":{"status":"ok","timestamp":1682617460040,"user_tz":-480,"elapsed":1163,"user":{"displayName":"陈冰冰","userId":"11790981709466704139"}},"outputId":"35a75099-8b02-4b0f-c305-b2ea1d1e9b00"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy:  0.9333333333333333\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import mean_squared_error, mean_absolute_error\n","import numpy as np\n","\n","# 假设预测值为 y_pred，真实值为 y_true\n","y_true = np.array([0.5, 2.8, 3.6, 7.1, 8.9])\n","y_pred = np.array([0.6, 2.6, 3.5, 6.7, 8.8])\n","\n","# MSE\n","mse = mean_squared_error(y_true, y_pred)\n","print(\"MSE = \", mse)\n","\n","# RMSE\n","rmse = np.sqrt(mse)\n","print(\"RMSE = \", rmse)\n","\n","# MAE\n","mae = mean_absolute_error(y_true, y_pred)\n","print(\"MAE = \", mae)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9NQ0xuskk-xA","executionInfo":{"status":"ok","timestamp":1682617466763,"user_tz":-480,"elapsed":3,"user":{"displayName":"陈冰冰","userId":"11790981709466704139"}},"outputId":"505fc3fa-6754-4b28-def2-71b874309357"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["MSE =  0.04599999999999989\n","RMSE =  0.2144761058952719\n","MAE =  0.17999999999999977\n"]}]},{"cell_type":"markdown","source":["## 反向传播的作用"],"metadata":{"id":"bieLXEj2nhoV"}},{"cell_type":"markdown","source":["反向传播算法是深度神经网络中最常见的训练算法之一，其作用是通过一定方式调整神经网络中各个权重的值，以使得神经网络对训练数据的拟合能力得到不断提升，从而实现更准确的预测或分类等任务。\n","\n","反向传播算法的基本思想是：先将训练样本数据输入神经网络，得到输出结果，然后通过误差反向传递的方式，计算并更新每个神经元的权重，以便下一次训练时使得神经网络的预测结果更加准确。\n","\n","具体来说，反向传播算法的过程可以简述为以下几个步骤：\n","\n","前向计算：将训练数据输入神经网络，依次计算每个神经元的输出结果，直至计算出神经网络的最终输出结果。\n","计算误差：将神经网络的输出结果与真实值进行比较，计算出神经网络的误差。\n","反向传播：将误差向后反向传递，依次计算每个神经元的误差贡献，并计算每个权重的梯度。\n","更新权重：根据计算出的权重梯度，更新神经网络中各个权重的值。\n","重复训练：重复执行以上步骤，直至达到预设的训练次数，或者达到了一定的拟合精度。\n","反向传播算法可以让神经网络能够根据训练数据不断自我优化，提高其拟合能力和泛化性能，使得神经网络能够更好地适应实际应用场景的需求。"],"metadata":{"id":"mKDE5xPVnnR-"}},{"cell_type":"markdown","source":["神经网络（Neural Network）是受到生物学中神经元的启发而设计的一种人工智能模型。神经网络由许多神经元组成，可以分为输入层、隐层和输出层。它们之间通过各自的参数进行连接，每个参数具有一个权重值，反映了对应的特征对输出的重要程度。\n","\n","输入层由接受输入数据（如图像、文本、语音等）的一组神经元组成。每个神经元对应输入数据中的一个特征，可以是像素、单词等。隐层（也称为中间层）是在输入层和输出层之间的一层或多层神经元，它们的作用类似于“特征提取器”，能够学习并提取出数据中的重要特征。最后一个输出层由输出神经元组成，每个输出神经元对应了一个分类结果或预测值。\n","\n","神经网络的训练是通过最小化预测结果与真实结果之间的损失函数来实现的。从前向传播中得出预测结果，再通过反向传播算法来更新神经网络中各个参数的值，使得损失函数最小化。这也是神经网络之所以能够对数据进行分类、预测等任务的原因。\n","\n","总之，神经网络的结构在很大程度上决定了其能力、效率和性能。设计高效的神经网络结构是一项重要的研究方向，能够提高模型的适用范围和精度。"],"metadata":{"id":"kVbhjGQap5EL"}},{"cell_type":"code","source":["import tensorflow as tf\n","tf.__version__"],"metadata":{"id":"vJ4k5LCHnkBm","executionInfo":{"status":"ok","timestamp":1682617711949,"user_tz":-480,"elapsed":4301,"user":{"displayName":"陈冰冰","userId":"11790981709466704139"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cdaca8ee-d7a2-428b-c630-3fbc1d88576b"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.11.0'"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["from tensorflow import keras\n","keras.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DooHlYFW0Qjw","executionInfo":{"status":"ok","timestamp":1682617735116,"user_tz":-480,"elapsed":4,"user":{"displayName":"陈冰冰","userId":"11790981709466704139"}},"outputId":"60ddeda5-ba0c-494a-fa56-350fb9008f33"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.11.0'"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["import ssl\n","ssl._create_default_https_context = ssl._create_unverified_context\n","fashion_mnist = keras.datasets.fashion_mnist\n","(X_train_full,y_train_full),(X_test,y_test) = fashion_mnist.load_data()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"uAOZMdV51QYf","executionInfo":{"status":"error","timestamp":1682618328354,"user_tz":-480,"elapsed":10446,"user":{"displayName":"陈冰冰","userId":"11790981709466704139"}},"outputId":"3b033e1f-c614-4af9-8111-7d8758226ec3"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","13352960/26421880 [==============>...............] - ETA: 1s"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [16], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m ssl\u001b[38;5;241m.\u001b[39m_create_default_https_context \u001b[38;5;241m=\u001b[39m ssl\u001b[38;5;241m.\u001b[39m_create_unverified_context\n\u001b[1;32m      3\u001b[0m fashion_mnist \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mfashion_mnist\n\u001b[0;32m----> 4\u001b[0m (X_train_full,y_train_full),(X_test,y_test) \u001b[38;5;241m=\u001b[39m \u001b[43mfashion_mnist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Desktop/网络与新媒体/projects/data_analysis/venv/lib/python3.10/site-packages/keras/datasets/fashion_mnist.py:93\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m paths \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[0;32m---> 93\u001b[0m     paths\u001b[38;5;241m.\u001b[39mappend(\u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_subdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirname\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m gzip\u001b[38;5;241m.\u001b[39mopen(paths[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m lbpath:\n\u001b[1;32m     96\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(lbpath\u001b[38;5;241m.\u001b[39mread(), np\u001b[38;5;241m.\u001b[39muint8, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n","File \u001b[0;32m~/Desktop/网络与新媒体/projects/data_analysis/venv/lib/python3.10/site-packages/keras/utils/data_utils.py:300\u001b[0m, in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 300\u001b[0m         \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDLProgbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(error_msg\u001b[38;5;241m.\u001b[39mformat(origin, e\u001b[38;5;241m.\u001b[39mcode, e\u001b[38;5;241m.\u001b[39mmsg))\n","File \u001b[0;32m~/Desktop/网络与新媒体/projects/data_analysis/venv/lib/python3.10/site-packages/keras/utils/data_utils.py:86\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m     84\u001b[0m response \u001b[38;5;241m=\u001b[39m urlopen(url, data)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fd:\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunk_read(response, reporthook\u001b[38;5;241m=\u001b[39mreporthook):\n\u001b[1;32m     87\u001b[0m         fd\u001b[38;5;241m.\u001b[39mwrite(chunk)\n","File \u001b[0;32m~/Desktop/网络与新媒体/projects/data_analysis/venv/lib/python3.10/site-packages/keras/utils/data_utils.py:75\u001b[0m, in \u001b[0;36murlretrieve.<locals>.chunk_read\u001b[0;34m(response, chunk_size, reporthook)\u001b[0m\n\u001b[1;32m     73\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reporthook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:465\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    464\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 465\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"P81fzsYV2PEk"},"execution_count":null,"outputs":[]}]}